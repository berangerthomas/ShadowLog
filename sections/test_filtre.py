import streamlit as st
import pandas as pd
import ipaddress
import plotly.express as px
import os

# ğŸ“Œ DÃ©finition du plan d'adressage de l'UniversitÃ©
UNIVERSITY_IP_RANGES = [
    "192.168.0.0/16",
    "10.0.0.0/8",
    "172.16.0.0/12"
]

# ğŸ“Œ Fichier cache pour accÃ©lÃ©rer les chargements suivants
CACHE_FILE = "logs_cache.parquet"

# ğŸ“Œ Fonction optimisÃ©e pour lire un gros fichier .log par morceaux (chunks)
@st.cache_data
def load_logs(file, max_lines=1000000):
    col_names = ["timestamp", "ipsource", "ipdestination", "protocole", "portsource", "portdest",
                 "regle1", "status", "interface", "inconnu", "regle2"]
    
    logs_list = []
    chunk_size = 50000  # Charger les logs par paquets de 50 000 lignes pour Ã©viter de saturer la mÃ©moire
    total_loaded = 0

    with st.spinner("â³ Chargement des logs..."):
        for chunk in pd.read_csv(file, sep=";", names=col_names, parse_dates=["timestamp"], dtype=str, chunksize=chunk_size):
            chunk["portsource"] = pd.to_numeric(chunk["portsource"], errors='coerce')
            chunk["portdest"] = pd.to_numeric(chunk["portdest"], errors='coerce')
            logs_list.append(chunk)
            total_loaded += chunk.shape[0]
            
            if total_loaded >= max_lines:
                break  # On stoppe aprÃ¨s max_lines lignes pour un chargement plus rapide

    df = pd.concat(logs_list, ignore_index=True)
    return df

# ğŸ“Œ Traitement des logs pour extraire les statistiques demandÃ©es
def process_logs(df):
    # ğŸ“Š 1ï¸âƒ£ TOP 5 des IP sources les plus Ã©mettrices
    df_top_ips = df["ipsource"].value_counts().nlargest(5).reset_index()
    df_top_ips.columns = ["ipsource", "count"]

    # ğŸ“Š 2ï¸âƒ£ TOP 10 des ports < 1024 avec accÃ¨s autorisÃ©
    df_ports = df[(df["portdest"] < 1024) & (df["status"] == "PERMIT")]
    df_top_ports = df_ports["portdest"].value_counts().nlargest(10).reset_index()
    df_top_ports.columns = ["portdest", "count"]

    # ğŸš« 3ï¸âƒ£ Lister les accÃ¨s hors plan dâ€™adressage universitaire
    df["is_outside"] = df["ipsource"].apply(lambda ip: not any(ipaddress.ip_address(ip) in ipaddress.ip_network(net) for net in UNIVERSITY_IP_RANGES))
    df_outside_university = df[df["is_outside"]]

    return df_top_ips, df_top_ports, df_outside_university

# ğŸ¨ Interface Streamlit
st.title("âš¡ Analyse OptimisÃ©e des Logs RÃ©seau")

# ğŸ“‚ Upload du fichier log
uploaded_file = st.file_uploader("ğŸ“‚ Charger un fichier .log", type="log")

# ğŸš€ CHARGEMENT OPTIMISÃ‰
if uploaded_file:
    if os.path.exists(CACHE_FILE):
        st.info("ğŸ“‚ Chargement des logs depuis le cache...")
        df_logs = pd.read_parquet(CACHE_FILE)
    else:
        df_logs = load_logs(uploaded_file)  # Charger seulement 200 000 lignes pour un affichage rapide
        df_logs.to_parquet(CACHE_FILE)  # Stocker en cache pour Ã©viter de recharger Ã  chaque fois

    # ğŸ“Œ Traitement des logs
    df_top_ips, df_top_ports, df_outside_university = process_logs(df_logs)

    # ğŸ“Š TOP 5 des IP sources les plus Ã©mettrices
    st.subheader("ğŸ“Š TOP 5 des IP sources les plus Ã©mettrices")
    fig_ips = px.bar(df_top_ips, x="ipsource", y="count", title="TOP 5 IP Sources")
    st.plotly_chart(fig_ips, use_container_width=True)

    # ğŸ“Š TOP 10 des ports < 1024 avec accÃ¨s autorisÃ©
    st.subheader("ğŸ“Š TOP 10 des ports < 1024 avec accÃ¨s autorisÃ©")
    fig_ports = px.bar(df_top_ports, x="portdest", y="count", title="TOP 10 Ports Destinataires < 1024 AutorisÃ©s")
    st.plotly_chart(fig_ports, use_container_width=True)

    # ğŸš« Liste des accÃ¨s hors plan dâ€™adressage universitaire
    st.subheader("ğŸš« AccÃ¨s hors plan dâ€™adressage universitaire")
    st.dataframe(df_outside_university)

    # ğŸ’¾ TÃ©lÃ©charger les rÃ©sultats filtrÃ©s
    st.download_button("ğŸ’¾ TÃ©lÃ©charger les IP hors plan d'adressage", df_outside_university.to_csv(index=False), file_name="ips_hors_universite.csv")

st.info("ğŸ“Œ Charge un fichier `.log` pour voir l'analyse.")
